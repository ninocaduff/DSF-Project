{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5f441a-65f1-47ac-baea-f40ec06cd051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a02fa7-4b43-42f9-90d7-604d6a5e8db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('finaldata/merged_df.csv')\n",
    "merged_df.drop(columns=merged_df[['PM2.5', 'CO', 'SO2', 'PN']], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2421b75-78a2-42cd-bc17-bdee557950a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including 'Street' in the subset for plotting\n",
    "merged_df['Datum'] = pd.to_datetime(merged_df['Datum'])\n",
    "time_series_data_with_street = merged_df[['Datum', 'Street', 'TotalDailyTraffic', 'NO2', 'PM10']]\n",
    "\n",
    "# Function to plot time series for each unique street\n",
    "def plot_time_series_for_streets(data, column, title, color):\n",
    "    streets = data['Street'].unique()\n",
    "    n_streets = len(streets)\n",
    "\n",
    "    # Creating subplots for each street\n",
    "    fig, axs = plt.subplots(n_streets, 1, figsize=(15, 4 * n_streets))\n",
    "\n",
    "    for i, street in enumerate(streets):\n",
    "        street_data = data[data['Street'] == street]\n",
    "        axs[i].plot(street_data['Datum'], street_data[column], label=street, color=color)\n",
    "        axs[i].set_title(f'{title} for {street}')\n",
    "        axs[i].set_xlabel('Date')\n",
    "        axs[i].set_ylabel(column)\n",
    "        axs[i].legend()\n",
    "        axs[i].xaxis.set_major_locator(mdates.YearLocator())\n",
    "        axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "    # Adjusting layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Showing the plots\n",
    "    plt.show()\n",
    "\n",
    "# Plotting time series for \n",
    "plot_time_series_for_streets(time_series_data_with_street, 'TotalDailyTraffic', 'Total Daily Traffic', 'blue')\n",
    "plot_time_series_for_streets(time_series_data_with_street, 'NO2', 'NO2 Levels', 'red')\n",
    "plot_time_series_for_streets(time_series_data_with_street, 'PM10', 'PM10 Levels', 'green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bff40-d603-4df7-bc58-03967c51d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding meteo data to merged df\n",
    "\n",
    "def import_and_transform_meteo_data():\n",
    "    streets = ['Zch_Rosengartenstrasse', 'Zch_Stampfenbachstrasse', 'Zch_Schimmelstrasse']\n",
    "    street_dataframes = []\n",
    "\n",
    "    for street in streets:\n",
    "        yearly_data = []\n",
    "\n",
    "        for year in range(2012, 2023):\n",
    "            file_path = f'meteo/ugz_ogd_meteo_d1_{year}.csv'\n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Filter for a specific street\n",
    "            street_data = data[data['Standort'] == street]\n",
    "\n",
    "            # Pivot the data\n",
    "            street_wide = street_data.pivot(index='Datum', columns='Parameter', values='Wert')\n",
    "\n",
    "            # Add the year and street columns\n",
    "            street_wide['Year'] = year\n",
    "            street_wide['Street'] = street\n",
    "\n",
    "            yearly_data.append(street_wide)\n",
    "\n",
    "        # Concatenate all years' data for the street\n",
    "        combined_street_data = pd.concat(yearly_data)\n",
    "        street_dataframes.append(combined_street_data)\n",
    "\n",
    "    # Concatenate all streets' data into one DataFrame\n",
    "    combined_data = pd.concat(street_dataframes)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "meteo = import_and_transform_meteo_data()\n",
    "#meteo.to_csv('meteo/meteo.csv')\n",
    "\n",
    "meteo = pd.read_csv('meteo/meteo.csv')\n",
    "meteo['Datum'] = pd.to_datetime(meteo['Datum']).dt.date\n",
    "#meteo.to_csv('meteo/meteo_dt.csv', index=False)\n",
    "\n",
    "meteo_dt = pd.read_csv('finaldata/meteo_dt.csv')\n",
    "\n",
    "merged_meteo = pd.merge(merged_df, meteo_dt, how=\"left\", on=['Datum', 'Street'])\n",
    "#merged_meteo.to_csv('finaldata/merged_meteo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d273d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769ac6d1-60ae-4cf7-bf75-fcffdab852b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_meteo = pd.read_csv('/Users/fredericksafian/VSCODE/finaldata/merged_meteo.csv')\n",
    "merged_meteo.drop(columns=merged_meteo[['Unnamed: 0', 'Year']], inplace=True)\n",
    "merged_meteo['Datum'] = pd.to_datetime(merged_meteo['Datum']).dt.date\n",
    "\n",
    "# Adding season dummies\n",
    "def get_month(date):\n",
    "    month_dict = {\n",
    "        1: 'Jan',\n",
    "        2: 'Feb',\n",
    "        3: 'Mar',\n",
    "        4: 'Apr',\n",
    "        5: 'May',\n",
    "        6: 'Jun',\n",
    "        7: 'Jul',\n",
    "        8: 'Aug',\n",
    "        9: 'Sep',\n",
    "        10: 'Oct',\n",
    "        11: 'Nov',\n",
    "        12: 'Dec'\n",
    "    }\n",
    "    return month_dict[date.month]\n",
    "\n",
    "merged_meteo['Month'] = merged_meteo['Datum'].apply(get_month)\n",
    "month_dummies = pd.get_dummies(merged_meteo['Month'])\n",
    "merged_meteo = pd.concat([merged_meteo, month_dummies], axis=1).drop(columns=['Month'])\n",
    "\n",
    "#adding weekday dummies \n",
    "\n",
    "merged_meteo['Weekday'] = pd.to_datetime(merged_meteo['Datum']).dt.dayofweek\n",
    "weekday_dummies = pd.get_dummies(merged_meteo['Weekday'], prefix='Weekday')\n",
    "merged_meteo = pd.concat([merged_meteo, weekday_dummies], axis=1)\n",
    "merged_meteo.drop(['Weekday'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d693247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding tree and green spaces\n",
    "\n",
    "#calculating trees around measurement points\n",
    "import re\n",
    "\n",
    "tree_locations_path = '/Users/fredericksafian/VSCODE/streetdata/gsz.baumkataster_baumstandorte.csv'\n",
    "tree_locations_df = pd.read_csv(tree_locations_path)\n",
    "\n",
    "def extract_coordinates(point_str):\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", point_str)\n",
    "    return tuple(map(float, numbers))\n",
    "\n",
    "tree_locations_df['coordinates'] = tree_locations_df['geometry'].apply(extract_coordinates)\n",
    "\n",
    "def calculate_distance(coord1, coord2):\n",
    "    return ((coord1[0] - coord2[0]) ** 2 + (coord1[1] - coord2[1]) ** 2) ** 0.5\n",
    "\n",
    "target_coords = {\n",
    "    \"Zch_Rosengartenstrasse\": (2682095, 1249940),\n",
    "    \"Zch_Schimmelstrasse\": (2681950, 1247250),\n",
    "    \"Zch_Stampfenbachstrasse\": (2683140, 1249040)\n",
    "}\n",
    "\n",
    "tree_counts_df = pd.DataFrame(columns=['Street', '1.5km', '1km', '500m', '200m'])\n",
    "\n",
    "for street, coords in target_coords.items():\n",
    "    tree_counts = {\n",
    "        'Street': street,\n",
    "        '1.5km': sum(calculate_distance(tree_coord, coords) <= 1500 for tree_coord in tree_locations_df['coordinates']),\n",
    "        '1km': sum(calculate_distance(tree_coord, coords) <= 1000 for tree_coord in tree_locations_df['coordinates']),\n",
    "        '500m': sum(calculate_distance(tree_coord, coords) <= 500 for tree_coord in tree_locations_df['coordinates']),\n",
    "        '200m': sum(calculate_distance(tree_coord, coords) <= 200 for tree_coord in tree_locations_df['coordinates'])\n",
    "    }\n",
    "    tree_counts_df = pd.concat([tree_counts_df, pd.DataFrame([tree_counts])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculating tree spaces around measurement points\n",
    "\n",
    "green_spaces_path = '/Users/fredericksafian/VSCODE/streetdata/gsz.gruenflaechen.csv'\n",
    "green_spaces_df = pd.read_csv(green_spaces_path)\n",
    "\n",
    "green_spaces_df['coordinates'] = green_spaces_df['geometry'].apply(extract_coordinates)\n",
    "\n",
    "green_space_counts_df = pd.DataFrame(columns=['Street', '1.5km', '1km', '500m', '200m'])\n",
    "\n",
    "for street, coords in target_coords.items():\n",
    "    green_space_counts = {\n",
    "        'Street': street,\n",
    "        '1.5km': sum(calculate_distance(green_coord, coords) <= 1500 for green_coord in green_spaces_df['coordinates']),\n",
    "        '1km': sum(calculate_distance(green_coord, coords) <= 1000 for green_coord in green_spaces_df['coordinates']),\n",
    "        '500m': sum(calculate_distance(green_coord, coords) <= 500 for green_coord in green_spaces_df['coordinates']),\n",
    "        '200m': sum(calculate_distance(green_coord, coords) <= 200 for green_coord in green_spaces_df['coordinates'])\n",
    "    }\n",
    "    green_space_counts_df = pd.concat([green_space_counts_df, pd.DataFrame([green_space_counts])], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "#merging it with the data set\n",
    "\n",
    "merged_meteo = pd.merge(merged_meteo, green_space_counts_df, on='Street', how='left', suffixes=('_green', ''))\n",
    "merged_meteo = pd.merge(merged_meteo, tree_counts_df, on='Street', how='left', suffixes=('','_trees'))\n",
    "distance_columns_to_rename = {\n",
    "    '1.5km': '1.5km_green',\n",
    "    '1km': '1km_green',\n",
    "    '500m': '500m_green',\n",
    "    '200m': '200m_green'\n",
    "}\n",
    "merged_meteo = merged_meteo.rename(columns=distance_columns_to_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#windspeed and humidity data is only in the hourly meteo set, so we will add that\n",
    "\n",
    "def import_and_transform_meteo_hourly_data():\n",
    "    streets = ['Zch_Rosengartenstrasse', 'Zch_Stampfenbachstrasse', 'Zch_Schimmelstrasse']\n",
    "    street_dataframes = []\n",
    "    parameters = ['WD', 'WVv', 'WVs', 'Hr']\n",
    "\n",
    "    for year in range(2012, 2023): \n",
    "        for street in streets:\n",
    "            file_path = f'/Users/fredericksafian/VSCODE/meteohourly/ugz_ogd_meteo_h1_{year}.csv'  \n",
    "            data = pd.read_csv(file_path)\n",
    "\n",
    "            # Filter for a specific street\n",
    "            street_data = data[data['Standort'] == street]\n",
    "\n",
    "            # Pivot the data to wide format\n",
    "            street_wide = street_data.pivot(index='Datum', columns='Parameter', values='Wert')\n",
    "\n",
    "            # Reset index to make 'Datum' a column again\n",
    "            street_wide.reset_index(inplace=True)\n",
    "\n",
    "            # Convert 'Datum' to datetime and keep only the date part\n",
    "            street_wide['Datum'] = pd.to_datetime(street_wide['Datum']).dt.date\n",
    "\n",
    "            # Select only the columns that exist in the dataset\n",
    "            cols_to_keep = ['Datum'] + [col for col in parameters if col in street_wide.columns]\n",
    "            street_wide = street_wide[cols_to_keep]\n",
    "\n",
    "            # Group by Datum, calculate daily mean\n",
    "            daily_mean = street_wide.groupby('Datum', as_index=False).mean()\n",
    "\n",
    "            # Add the street name to the DataFrame\n",
    "            daily_mean['Street'] = street\n",
    "\n",
    "            street_dataframes.append(daily_mean)\n",
    "\n",
    "    # Concatenate all streets' data into one DataFrame\n",
    "    combined_data = pd.concat(street_dataframes, ignore_index=True)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Use this function and export the result if needed\n",
    "meteo_hourly = import_and_transform_meteo_hourly_data()\n",
    "\n",
    "\n",
    "\n",
    "#merge it\n",
    "\n",
    "merged_meteo = pd.merge(merged_meteo, meteo_hourly, how=\"left\", on=['Datum', 'Street'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a0e6216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Street</th>\n",
       "      <th>messwert_von</th>\n",
       "      <th>messwert_bis</th>\n",
       "      <th>temporegime</th>\n",
       "      <th>temporegime_technical</th>\n",
       "      <th>umgesetzt_datum</th>\n",
       "      <th>rechtskraeftig_datum</th>\n",
       "      <th>publiziert_vsi_datum</th>\n",
       "      <th>ausnahmen_fahrverbot</th>\n",
       "      <th>fahrverbot_ssv</th>\n",
       "      <th>objectid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>619</td>\n",
       "      <td>Schimmelstrasse</td>\n",
       "      <td>0.000</td>\n",
       "      <td>261.419</td>\n",
       "      <td>T50</td>\n",
       "      <td>T50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>1246</td>\n",
       "      <td>Rosengartenstrasse</td>\n",
       "      <td>0.000</td>\n",
       "      <td>461.979</td>\n",
       "      <td>T50</td>\n",
       "      <td>T50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4052</th>\n",
       "      <td>5106</td>\n",
       "      <td>Stampfenbachstrasse</td>\n",
       "      <td>404.849</td>\n",
       "      <td>1298.793</td>\n",
       "      <td>T50</td>\n",
       "      <td>T50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>4527</td>\n",
       "      <td>Stampfenbachstrasse</td>\n",
       "      <td>0.000</td>\n",
       "      <td>98.543</td>\n",
       "      <td>T50</td>\n",
       "      <td>T50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>4528</td>\n",
       "      <td>Stampfenbachstrasse</td>\n",
       "      <td>98.543</td>\n",
       "      <td>404.849</td>\n",
       "      <td>T30</td>\n",
       "      <td>T30</td>\n",
       "      <td>2.018110e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5162</th>\n",
       "      <td>5183</td>\n",
       "      <td>Rosengartenstrasse</td>\n",
       "      <td>461.979</td>\n",
       "      <td>506.905</td>\n",
       "      <td>T30</td>\n",
       "      <td>T30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>5184</td>\n",
       "      <td>Rosengartenstrasse</td>\n",
       "      <td>623.947</td>\n",
       "      <td>858.376</td>\n",
       "      <td>T30</td>\n",
       "      <td>T30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5164</th>\n",
       "      <td>5185</td>\n",
       "      <td>Rosengartenstrasse</td>\n",
       "      <td>506.905</td>\n",
       "      <td>623.947</td>\n",
       "      <td>T20</td>\n",
       "      <td>T20</td>\n",
       "      <td>2.023051e+13</td>\n",
       "      <td>2.023011e+13</td>\n",
       "      <td>2.022121e+13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               Street  messwert_von  messwert_bis temporegime  \\\n",
       "2013   619      Schimmelstrasse         0.000       261.419         T50   \n",
       "3420  1246   Rosengartenstrasse         0.000       461.979         T50   \n",
       "4052  5106  Stampfenbachstrasse       404.849      1298.793         T50   \n",
       "4509  4527  Stampfenbachstrasse         0.000        98.543         T50   \n",
       "4510  4528  Stampfenbachstrasse        98.543       404.849         T30   \n",
       "5162  5183   Rosengartenstrasse       461.979       506.905         T30   \n",
       "5163  5184   Rosengartenstrasse       623.947       858.376         T30   \n",
       "5164  5185   Rosengartenstrasse       506.905       623.947         T20   \n",
       "\n",
       "     temporegime_technical  umgesetzt_datum  rechtskraeftig_datum  \\\n",
       "2013                   T50              NaN                   NaN   \n",
       "3420                   T50              NaN                   NaN   \n",
       "4052                   T50              NaN                   NaN   \n",
       "4509                   T50              NaN                   NaN   \n",
       "4510                   T30     2.018110e+13                   NaN   \n",
       "5162                   T30              NaN                   NaN   \n",
       "5163                   T30              NaN                   NaN   \n",
       "5164                   T20     2.023051e+13          2.023011e+13   \n",
       "\n",
       "      publiziert_vsi_datum ausnahmen_fahrverbot fahrverbot_ssv  objectid  \n",
       "2013                   NaN                  NaN            NaN      7350  \n",
       "3420                   NaN                  NaN            NaN      8757  \n",
       "4052                   NaN                  NaN            NaN      9389  \n",
       "4509                   NaN                  NaN            NaN      9846  \n",
       "4510                   NaN                  NaN            NaN      9847  \n",
       "5162                   NaN                  NaN            NaN     10499  \n",
       "5163                   NaN                  NaN            NaN     10500  \n",
       "5164          2.022121e+13                  NaN            NaN     10501  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the speed limits \n",
    "\n",
    "speed = pd.read_csv('/Users/fredericksafian/VSCODE/streetdata/taz.view_geoserver_tempo_ist_e.csv')\n",
    "speed.rename(columns={'lokalisationsname': 'Street'}, inplace=True)\n",
    "streets = ['Rosengartenstrasse', 'Schimmelstrasse', 'Stampfenbachstrasse']\n",
    "\n",
    "speed = speed[speed['Street'].isin(streets)]\n",
    "speed\n",
    "\n",
    "#all the same anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d22d48d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NO2_tomorrow (target variable) column by shifting the NO2 column up by one row\n",
    "unique_streets = merged_meteo['Street'].unique()\n",
    "data_separated = []\n",
    "for street in unique_streets:\n",
    "    df_street = merged_meteo[merged_meteo['Street'] == street].copy()\n",
    "    df_street['NO2_tomorrow'] = df_street['NO2'].shift(-1)\n",
    "    data_separated.append(df_street)\n",
    "\n",
    "merged_meteo = pd.concat(data_separated)\n",
    "\n",
    "merged_meteo.head()\n",
    "\n",
    "\n",
    "\n",
    "#merged_meteo.to_csv('/Users/fredericksafian/VSCODE/finaldata/merged_with_dummies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "114902f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Datum', 'TotalDailyTraffic', 'Street',\n",
       "       'NO', 'NO2', 'NOx', 'O3', 'O3_max_h1', 'O3_nb_h1>120', 'PM10', 'PM2.5',\n",
       "       'CO', 'SO2', 'PN', 'RainDur', 'T', 'T_max_h1', 'p', 'StrGlo', 'Apr',\n",
       "       'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct',\n",
       "       'Sep', 'Weekday_0', 'Weekday_1', 'Weekday_2', 'Weekday_3', 'Weekday_4',\n",
       "       'Weekday_5', 'Weekday_6', '1.5km_green', '1km_green', '500m_green',\n",
       "       '200m_green', '1.5km_trees', '1km_trees', '500m_trees', '200m_trees',\n",
       "       'WD', 'WVv', 'WVs', 'Hr', 'NO2_tomorrow'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_with_dummies = pd.read_csv('/Users/fredericksafian/VSCODE/finaldata/merged_with_dummies.csv')\n",
    "merged_with_dummies.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0926ffc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
